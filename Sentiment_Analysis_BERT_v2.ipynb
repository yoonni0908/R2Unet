{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F24pbMKw8uT9"
      },
      "source": [
        "<h1>개인 구글 드라이브와 colab 연동</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X-lNQfT1D1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6998862-5c27-4ca1-d057-aa1326f9fe84"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4B-rbK8b3TW",
        "outputId": "56ac9574-3925-4838-f06d-6d2717214844"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "\n",
        "root_dir = \"/gdrive/My Drive/NLP/week3/4-2. Pretrained LM1\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(root_dir)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.97)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdbZmdUt-d8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "300ca846-f2a5-470d-fb7e-72842a56d1b9"
      },
      "source": [
        "import os\n",
        "from IPython.display import Image\n",
        "Image(os.path.join(root_dir, \"BERT.png\"))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAGNCAMAAAB+AE/oAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAEjUExURQAAAAAAAAAAAP///wAAAAAAAP///wAAAAAAAAAAAP///wAAAP///wAAAAAAAP///wAAAAAAAAAAAP///wAAAAAAAAAAAAAAAP///wAAAAAAAAAAAP///wAAAAAAAAAAAAAAAAAAAAAAAAAAAP///wAAAAAAAAAAAAAAAP///wAAAAAAAAAAAP///wAAAAAAAAAAAAAAAP///wAAAAAAAP///wAAAAAAAAoKChERERoaGh0dHSMjIzQ0NDg4ODw8PEFBQUdHR0lJSVdXV19fX2lpaXBwcHFxcXp6eoODg4mJiYqKiouLi5SUlJeXl5iYmKSkpKenp6ioqLW1tby8vL6+vsPDw9DQ0NfX193d3d/f3+rq6uzs7PDw8PHx8f39/f///0VDtlwAAAA3dFJOUwAMEBAdICAkKzAwQEBHUFBRV2BgZGhpbHByd39/i4yPn6Klra+0uLq/v8XLz8/V2d7f3+nv7/IO5mBRAAAACXBIWXMAABcRAAAXEQHKJvM/AAAnB0lEQVR4Xu2dC5/rtLXFS6GlLZd74RbK+/RCCz2FHqC8RCABctLAkAJDOpAhhwDz/T/F3XtrSZYTO+PMeCJNsv6/cyaKbMvLyl6WLL9+RQghhBBCCCGEEEKy8fD/3Hv/goD3//pH1Ash++LhvyL8CLj3MKqGkL1AD25yD3VDyF74IwKPJLBHSvYJG8IG3kflELIP3kHckQSakOwThB2pgcohZB8g6kgNVA4h+wBRR2qgcgjZB4i6m+HEDc+R3CPzwWCOpHE+dCdIdgWVQ8g+QNTVmDnnRkhfSHqG5K6cy7ITpK+PFGaMT1fIaWHg3ABJYyIL7bgvQOUQsg8QdTXUhNF5SbIrq/nkVD9vxoTusuY1mHB5Ol7oJ01IygZRV8NM6Jb+i6R2NWFcpNfuqInyDJHVDLqjC5nRTMjuKCkbRF0Nb8Kx/yKpK5uwV3ypq7k0dK52zNdCNOEVQOUQsg8QdTXUhBLq1qUszYQXF2eS6NKy0YTkloCoq6EmnIsPrUMaHbWajaQjOEUvdSFHWsN5mLo6nYhrRzMdMpEsQ/L170omTG2RpXxVYy903vFGYzbX7FC+LTmpDbD4In1CW+nlieipyrFS3Ui6v2OdrhY0FrY59scXPfWHjPXNWQOVQ8g+QNTVsKi1UBYkbbEvR1bGwI7yTvyXU/mvUzX+lZG4EMlgwhD0Fxc6s0zHonBmYCXr85ir5FNN4myaR7NCYqJHfvKp6DrNWoa0fY0mDHsA0yoNaX1z1kHlELIPEHU1fNRKsJ7JF0lr7GuDJg2dGGkgQa9dwoBORdK+IIXkzOygBekopRhPCh8tLpbiMG8poI4D6kL5MJf4iYZ8syWkjZZEokBdqJnisbNJmwk110676JDtcm1zNkDlELIPEHU1fNQiQCWtsS8tjZ1tkFiWYFeDnK4uzrQ10qmDEwl+NZbFOTJDQmbWVm8l38R98lcbHzFJ2tdUE2lXUts3zZevbrS8SDuLkiOF+YGZZVCw1PMPIkgkYyAJJkyOCf3m6Bq0OGmIZWp9czZA5RCyDxB1NXzUauMkgSppsxmaM5k2sdbEYlcDXadaa7LQ/qYmkBkSEvZ6TkFcIB8yj78OQKYlPUExw9AKUa+IdeTvehMlWQHfvHr3iBvFVCo5HB02m1D3ATqHzC8ftc3ZBJVDyD5A1NWACdVqZzCSpgPjcHQnSEL9tpxqy6QkmSGBxk/aLLGNtlwBs4hHvmHEU1KyjPytHzNaFpDpKtEr8GLVu27kr6VpNiEaP9kQaWnrm7MJKoeQfYCoq4Go1c+hNiAS9BrRgXGcIVhmoV1ENwojKT6zSkj+ibVE0h0Uh0TqJvSLIFV9j+gSgh/QrBQgheEedXKLCfUocqXzibvrm7MJKoeQfYCoqxEjXJo3DW6xQ4xoY92EMp9aQ2eqMquEdUTFA9rxg0PWiYtoShrM6nukllUzoR1cLvz4qLiwxYS+Iyo7BGmV65uzCSqHkH2AqKsRI1xjVRo5iX1tx9A/lC6fdv7sCEwTM+tv6rewnHz4vqVN9QsvxSN6FKamxnBLeswnxvHXommJ4hIsmVLLUmX+GFCshaM6G7MRQyYmDMd9JksbQZGqh6T1zdkElUPIPkDU1YgmRCdPY18i252Ie85PJOTVdXp9po1UxlGSU/2mS6mjlhrdNlUQA8pEc5nOOxRvrOb+6mqg3ptgdFTnC0sm1LPEe4M5RkdFibeSFw4T6gKTlUwJmyOqB3I0a96tbc4mqBxC9gGirkZlwpXEuo99NY9HA9x3/cQv8l+mqvvwTZfygy+S7//a4ZgdFyoa/p5af1CPJ4Hmy0fiOKOelZwnVEHjqSyl50jEU8GEXlU4TyjIZPlnfq1vzgaoHEL2AaKuRmVCH+sW+9pWGdp0rLxnBjrKKFN1AQlwnVln9REu+f6vYH7wvVAsKiRnKJJsf0OuJBLHGWtZUc9YXRWsLS1wNKFXlZhQB3VDL7S2ORugcgjZB4i6GokJrVXzsW+nIQYTfyS2mskX6T/KVD1dNxcLTVdqPpt6po6SGeOy2q2NTc5cHTPSzmCN+VisGrLjkhXrWcuprCXoObEm29/vG0x4oRoH59Xm6JFgbH9rm7MOKoeQfYCouyLa9tV6lQcCKoeQfYCo2xE/DuL7kEgfFKgcQvbB1V7INBvPpdtovc71C1sOAlQOIfvgHsJuN/yYh9J4E8Jth2+EIfvkai+EsXFGRe98ODxeROUQsheu1hTafezDlrHF2w5fUEj2y8NXc+EBc++3qBpC9sWztGHF+/eeZTtIjpXHfo8EISQPd/+BBCEkC485x6aQkJzcdY5NISEZkYaQTSEhOZGGkE0hIRmxhpBNISH5sIaQTSEh2UBDyKaQkFygIWRTSEgmYkPIppCQPMSGkE0hIVn49QuKc/aBPELI3nEOCUJIHmhCQjJDExKSGZqQkMzQhIRkhiYkJDM0ISGZoQkJyQxNSEhmaEJCMkMTEpIZmpCQzNCEhNw0z7z8Ju5XuhJvvvwMCiKEXIXf/Q1mugZ/+x0KI4TszO/go2tCFxJyVbQd/Pe13ih6/m8p4m8ojhCyI8+Igf4DN12Z/0ghPC4k5Gq8LO0grHQNpC18GQUSQnbjTed6eLv9uXNvokBCyG5IRxJGuhZSDAokhOwGTUhIZmhCQjKTmHAmac/YfxlhglpsJh8L+RwsfdbF2GYLyBQUSAjZDXEPfLRpQnOegqSaMDqPJiSkH8Q98FGDCR2aPUlFE7q5z6MJCekHcQ98ZL5DMpgQNpNUZcLByvJoQkL6QdwDH22acODcqX2RdDwmdG5ieTQhIf2QGG/DhPMwDiPpYELJc2eaRxMS0g/iHvho04TRaJIOJlzIBOuQ0oSE9ENivE0TLqXzqc2epKMJL0bOncgXmpCQfkiMp77zLIIjT32zJ+nKhOd+BpqQkH4wr3kaTKjN3mTNhBcnzg1XNCEhPeG9ZjSZUJu9szUTrobaIaUJCekH7zUDvvOEL/I5XEk6MaF9ntOEhPQDvKY0mvBCmz1Jpya8mDo3ogkJ6YfEeM0mVOcN1ky4kgz5RxMS0gOJ8ZpNqOMwQs2EF2eWRxMS0gPiHviozYQ6DrNuwouJ5tGEhPSAuAc+ajOhb/bWTKin8WlCQvpA3AMftZrQmr01E+ppfJqQkD5IvHYdaEJCrgpNSEhmaEJCMsOH/xKSGT4Gn5DM8IUwhOSGr0YjJDN8SSghueHrsgnJzjMvvwkzXYk3X+bxICE3ye+d+28kCSE5+D/n/okkISQD0hCyKSQkJ9IQsikkJCO/eU9N6P4XXwkh+8YaQjaFhGQDDSGbQkJy8Wd40L2HDELIXokNIZtCQvLwAhwosCkkJAcv/Flw7s8vCL9BHiFk3/zT0X+EZOUf7vdIEUKyQBMSkhmakJDM0ISEZIYmJCQzNCEhmaEJCcnMXfcYUoSQLNCEhGSGJiQkMzQhIZmhCQnJDE1ISGZoQkJy8NCTz9155e5bH+CWXkJuJx+8dfeVO889+RDi+vbwyNOvYhMIOQxeffoRRPet4PnXoZuQQ+L15xHhxfPU217xJ1989e33P/yMF4EScjv5+Yfvv/3qi098UL/9FKK8aJ54w8Te//oBtoGQQ+DB1/ctst94ApFeLI++pjo//uYnKCfkcPjpm481vF97FNFeJo+/Kxo//PIXiCbksPjlyw8lwt99HPFeIn/S/cTnP0IwIYfHj59rkP8JEV8ed0TdR99BLCGHyXcfSZy/hJgvjb+Itk85HEMOnQefSqT/BVFfFi+Jsn9BJiGHzL8k1u8g7ktCjwc/g0ZCDpvPJNrLOy58nO0gOSK0LSxtjPTRd+V4EPoIOXzkuPDdws4XvubcRxyTIcfDg4+cew3RXwZPSOPMcxPkmPhOYr6oK9jecO5zaCPkOPjcuTcQ/yXwlHMf8joZclz8+KFzBd1T8bZzX0IZIcfCl869DQfk53nnPuY12+TY+OVj54q5y/d1576BLkKOh2+cex0eyM0jzjneP0iOj58k8gt57szTzt2HKkKOifvOPQ0XZOZV576GKEKOia+dexUuyMtD0ibzYhlyjDyQ2C/ieaRPOvcJNBFyXHzi3JPwQVaec+4LSCLkuPjCuefgg6zcce4rSCLkuPiqkJt7X3HuW0gi5Lj41rlX4IOs3HXue0gi5Lj43rm78EFW3nLuB0gi5Lj4wbm34IOsfOAc3zdBjpOfnfsAPsiKcw6KCDk2JPrhg6zQhOR4oQkJyQxNSEhmaEJCMkMTEpIZmpCQzNCEhGSGJiQkMzQhIZmhCQnJDE1ISGZoQkIyQxMSkhmakJDM0ISEZIYmJCQzNCEhmaEJCckMTUhIZmhCQjJDExKSGZqQkMzQhIRkhiYkJDM0ISGZoQkJyQxNSEhmaMLSWE3dYIb0jsykGo+0Hhe66Qt8WWMsk8ZIF4nogw+yUnbwWHAbw8l8hcybwlY2x5fdaDZh8TFoqHSpX3wz5j6vxVp1aMLrIzIgqEQqEwqDqxmkMxoy7mpN4e03Yc1HVhM04d4QGRBUIjUTXrGZOp+NOkXTcbeEboqvwhJZNOGeEBkQVCJrJnRL5HfnfCCLdTNh78eEt8qEg6q3H2qdJtwTIgOCSiQG92KqKXdiubuwLUb647abcCT/qz7AUA4RNZcm3BMiA4JKJAnuU02OfHoHaMLLUOk1pVplmkET7guRAUElkga39it310oTXoZKN/2hr6+dDtvl0YR7QmRAUImkwW07Z/m0vMXFbBg6p/OJ+HM4aRpS0VmBxIkvYTUduDOZtppPx7LgYBwWjCvDGpZT6ZTFqcLyRLtt45PqyHShqx7NVqnOis0YPJ+NtYjRNBShy8ksc5l1GDOxpuFsFabDKjYtLfbsZKwdx7HMGVidyvSBlOW3FlxSRwst5RQZOmfdWoupqh5O08WtdkRzbc61GtqsgMIQffBBVkQGBJVIuwntGFGzz/VnN8abJxIxRQkmXFmYyHL6xTM6t5nXTDiXYFTisKFlK+FcycoKFIYn+tdnJmzE4ERn88BQmhyHcgZeh1gGqx6t9G+7CTGbMNDdinJuR3NalhWKzMvqaKEbgFOFepJwllrLl2SgpgTbYmHgK8tnrtfQRgWUhuiDD7IiMiCoRKIvBI24gXxanh+nkW82+glGGxGGCUowoS0pkWFhBvyhZlyZJU5jwbCcX6XHsszOCTZXykYMVtHsrDGGCWPJiQ08tkC7CTUTDHzjU1XHwNStZbbV0cLOSniH6Z4ibd/SpeN+Iq0Mwc+5UUMbFVAaog8+yIrIgKASSUzovRcSHjGCRshYIuNMY27jBIPN5QkmNMyEg6nkLS1yLGTqJqxCz1tDMwenq4ulJTSUQ2MQsNlSNmJw7EZzMcuZlu1L1eWSIDcdyzTqhW0mnJytpAOqE32DvbZfME0d6mhhC1oRasdRcqRnS1f4Mxln+BawOTdriCbshsiAoBIxO2hi4Xty+mNbnhudycGd/zLRGSx4tKFcI+1XeRNOzuXQRUtMDlysiLgyvwYJW3+sZyMWFou+GVDbyvGTP6WtB3Jz3wW0iSkbMRiOyUyUFaYJi9yF2cdsYLuF4Vyi2Tct7SYMVyGoTNt2a0MHs6Uo994JU7fUkc62sCVtkjp6nlRbVLMyD/sDcdvgsUxf+DrVOTdriCbsiMiAoBLxJohYjFpeOLVc/fAIpnU2TBiCInbLtDxrlqzgmPBdVPO+Lq6x6SPZJksp1v54X/jWwpIpGzEY16mzmyE14Xumdoxqc2th2D5TYpma2DBhKM82UncVUS7yTNMldeTz7OhTJam/ZJ/gc4VEzUqnqVMrrajU5hqiCTsiMiCoRCwII/4ntjwMjPpIq5BgqLKqORB3Fi9hBMOzWMxsV69pKzgm/HzW79LFbdkKCS3NCc1Kx4EZY7mYzzSazVK6HE5+ajujc5viMFKpaStCExsmNM4XpyZYVeonjOAVy2dDHdVAnlaDLKr+ko9YbZZAA+73O+JnWx98vaWGWiqgIEQffJAVkQFBJWK/dgAxGCNOqIYwPBK7VczZHDGahBCWHhvLD2iGFRwTfpm4uO9xRsR9mhMC3iIR6YrNGFzouD6IJsQsYW7bJkR4VYRmbprQzjwAUWk95ODfsDkNdVRD82RZ24SleVH2P3G7zXfouMdcnSnsf6wJba6hhgooDNEHH2RFZEBQiVQmHJ+GSEhNWE33SJh2NaGNjkQ0J0Rtuoa4uH6m1GzhZ0O6Yj0GV8kpinYTRhlKLEIz101YnXlQRGW6sbGchjqqoXm6jJroVHufap9YUk1NyK1tGPLsM0Wy1iugOEQffJAVX1ulUgsBYHmINEsHdzaSxqXGRCgtDEGO/AkCzYorS9YQF9dPPwAZ0JxwLau1F0hXrMcghlMHY2sPt5owHO3pjDZdM9dNCA8Ox1awqDS1ob8dtuuyOtLJuoVayEhL0I2K293YEqqCcAWhHR8219BGBRSH6IMPsiIyIKhEoi8SEov4qAhHLI3EaBI0JkJpFqIzjS6bQ7PiypI1xMV1WZzGA2qBEInRyDXWYtA6iyPziE5pM6H1C7FNtohN1wQ6v7r70DzrZ06s46opUWldw2AE6x7K52V1pJN1C21d6kQtMW53bengSDM99hOmormG1iugPEQffJAVkQFBJXKZCS1whqHZCJ8paRBpTITSNO3bsbr3YsKvIQaj2SweTumarG/pS/ZX31gyZS0GrSyvUVNtJrTCcE7d1mHT1fJ+kNKcoHkq0+8Fokr1J86n22yq6bI60sm2sVY9MFIs0XwNNTYIrJOtbG92GzFtqaH1CigP0QcfZEVkQFCJRF8kJBZB4Az1DPhqcRLGClIsmkbLi5VEhc2MfE2bDXwUaWqrCS3h9PT+xfl8rEv6AQ89J4eLa3T+GmsxaEVYyoK4zYS+CdMW89wfQ1qmJUfnODNveSrTL2sToxEGeorRtsGv7pI60qm2sRjBMR/F7fZFjvSaAH86VHc75mtrhM8sr6WG1iugPEQffJAVkQFBJRJ9kZBYJPzyAWSm2J5ckSUsGpGvab3g0p+Btty4smQNVTDawgELMR9/hrlQ82rUFnG+rOkyGKTVhMlwppVrmd57hq5X86yY01Xwqqr07vBETZfUkWbaFuLaGDsArLZ77fod3/SaMz02uaWG4iaViuiDD7IiMiCoRKIvEhKLCBjs8CCvRggNWcKSyK4iPQZrXFmyhpZgtBCrgnvLBdwViWutqFYTJsuZ9SwTDhFOwoyV4yojmHRjUm3t9jrSTL+xZi1/4Fltd7pPkDWZRRM1yU1PmzVUbVKhiD74ICsiA4JK5HITXlQXWsdTVzXC9ceyRBWWQtiZT+veiwm/hiQYl5U3cOgTbnYYnDfp3DRhkDKww752E8a7M6Y23R+6hoWn1YzBHqN4wrwy3MgKwcDR1jrS3GRj/VFust3xxgwh3oQR8+bbaqjapEIRffBBVkQGBJVIU3AnFjGWp3pboBtNW56JaDe+uaEcwFiMIFdCWL4OJos178VEEpdhZWd2W91gPPNDH1J0uO2vSeemCb2UEW4TbDehaNOT8KKtmjEsLB6pZrTbGcfplZ6Stznb9jpKlpUlcYVabbtFjlbh6CRmyI4i3La4rYZSCUUi+uCDrIgMCCLlUTWZu6OuK9oBBUATkhaq1ioOe3alWrQagSWtSBXBB1kRGRBESiHev24HfY1Hum1MwvUy/hAyFESakSqCD7IiMiCIlIJzU/HS6kwPqXZszcZyiCitIZ4Qyd7oJUgdwQdZERkQRErBDBTYfB7FNrxvQXxmDWlBKgk+yIrIgCBSCuYgMPIn5rqSmnCwy8HkcSK1BB9kRWRAECmF5NFK053aQenD+guAFH2qDNmOVBN8kBWRAUGkGPz9xsPqHsodsFOMg/EJLdgBmpCQzNCEhGSGJiQkMzQhIZmhCQnJDE1ISGZoQkIyQxMSkhma8DahV6LoVZzVZWGj6o2bdktvwC6arnIG4Yx7bSZj8/JqTBDG9sCkq6H32fMepk5ITcEHWREZEES2MMHl0LULpPVufWWbCRVzxG4mFBre59kRXVW4pYlsQyoKPsiKyIAg0o7e2BefmlKB2xQuM6E9JWZnE+54/0SKNNvhtVVkG1LL8EFWRAYEkVb04WL+4dJ1E8JHl5owvsmoxmUmvHqfUp/7Et5VQ7Yg9QQfZEVkQBBpRW+R9cdoakI1D96Y6R+obf7SRCTm+OewxXdWVAU0orOq85b+OW7hIfu7o4/F4I1MlyPVBB9kRWRAEGlDH/CJtyxUHqqe/77NhHjWS2W7TibEE56u/svo4q1rIRGpJvggK9f5qY8FtRSGQhMPadI/rnqrCe0R4Dub0JJrr1fZBV3NFe6DOjakluCDrIgMCCJtaJuHcY41E3qbbDWh2elqJsT7lc5nY+37jvT1+GBpj+F2g3jjrt1FOKzOmuhIUtUHJi1ILcEHWREZEERaSPt2lYeSR4JuNaHNV723r6MJq4fL+8ceemDQ5Ln2fpbqbaHhvIa2v9doSI8FqSX4ICsiA4JIC2qIEP7BQysbOoG3tprQmqxqkKSTCf0rY5IecMCf/UveLWEFJ4/DiOc11Jbsj16GVBJ8kBWRAUGkhWpstO6I2N8zywRszmhC/9jCxHWXmjAwCF3LsRvpa83s9d7WuNmLYPS9ZOenQ12bvZ1FO6Y2YovdhYrmCfvLkEqCD7IiMiCItKC+CY1KYsLBSchsMWEkPeve1YTD07BQONCzlz7oMaA9Ejh0O+W/rsyfFVR74lnBmhmab9KGVBJ8kBWRAUGkBW1okExNKEy8FS4xYe2JaZ1bwuihuLTmqSGt8NA0C6oPAzTVFF5A2gWpJPggKyIDgkgLGtlIrpkQbdxWE649/bNuQmvdDPuKdKAazrlYLuYzHaRVX9lC+jpeT1WGx69Pc1vNToBUEnyQFZEBQaQFjWwkKw8t/cujzSdmOU1EUlvWn4N9qQmt+Tqf2ViL74jay86ATbVpsm5/zBfeUhjw706kCbsglQQfZEVkQBBpQSMbydRDNh5iR2AtJpRZ7BNvt/V0MyGm6JHeKjlFESwKFzobl0kNr/gCaMIuSCXBB1kRGRBEWtDIRrLmIU3bwVirCXG+L70GtG7CNXRmmNDSanGcjxiMrT30U5fhNcPa97R1bZyNUBMm3VnSiFQSfJAVkQFBpAX1TTo6WjNhbIt8HqhyrB0LxhJ2MqEUYecjRtbx1EXD1NXcn58Xf1ubGc5nRFRBslrSiFQSfJAVkQFBpIX0loTEQ75TqKltJlzaXNVhYVcT2pGezGgW82Mwmkp8tTQbwqbDMEwTPrUB3XAmWUMqCT7Iiv2OZBtpoxI9lN5ttM2E6x3Sbias7oAyE9pEK0inBp+ZT+VTi3RDPaG/WpyEV4pqZm1EiDQglQQfZMX/jmQL69eOplg/0TsmsN5BtUViC3apCRN0RMdMOF3iSjYrZzY81XXY9THqbpslouUIktrpFb/HidQSfJCV6mcjbazdRZHghz62m7DeId3FhNadjKcnrBgzoX31WDc5uZY0rFXP1fPe+kuRWoIPshJ/NtKKBrk/+1Y34QCZ203ov4QOaXcT2vmH6nzEIN62Ua1ugKtDTzGPgOaPl452QmoJPsiKyIAg0sbanfWewThe3XmJCe2OhtAh7WjC5NbApZ6bGM1WNlVLmXsRMksQcLE8HasPR1Nk8U6mbkg1wQdZERkQRFq5dUONuhOA68kWaMLbgz1tLTY75VM9HY5shSa8Reg4xy16WkR6ByTZAk14m9AO6a0Z6Lhlu4yM0IS3Cmlc6rdDlIueE2kd+yEpNCEhmaEJCckMTUhIZmhCQjJDExKSGZqQkMzQhIRkhiYkJDM0ISGZoQkJyQxNSEhmaEJCMkMTEpIZmpCQzNCEhGSGJiQkMzQhIZmhCQnJDE1ISGZoQkIyQxMSkhmakJDM0ISEZIYmJCQzhZjwA+d+hiJCjoufnfsAPsjKW879AEmEHBc/OPcWfJCVu859D0mEHBffO3cXPsjKK859C0mEHBffOvcKfJCVO859BUmEHBdfOXcHPsjKc859AUmEHBdfOPccfJCVJ537BJIIOS4+ce5J+CArDznnHkATIcfEA4n9h+CDvLzq3NcQRcgx8bVzr8IFmXnaufsQRcgxcd+5p+GCzDwibfJPUEXI8fCTRP4jcEFuXnfuG8gi5Hj4xrnX4YHsPO/cx79AFyHHwi8fO/c8PJCft537EsIIORa+dO5tOKAAnnLuwx+hjJDj4McPnXsKDiiBN5z7HNIIOQ4+d+4NxH8RPOGc+w7aCDkGvpOYfwLxXwavOfcRL5shx8ODj5x7DdFfCI++69ynkEfI4fOpc+8+iugvhcelcf4X9BFy6PxL4v1xxH45/ElUfQaFhBw2n0m0/wmRXxJ32BaSI0HbwZcQ92XxF1H2KUdnyKHzQI4H3V8Q9aXxkmj7iGcqyGHz3UfFtoOKHhe6z3ntDDlcfvxcg7zE48HA4++KwA+/5NXc5DD55csPJcLfLW9cNOXR13Q/8fE3vL+QHB4/ffOxhvdrpZ0f3OCJN1Snu/81h2jIIfHg6/sW2W+Uda1aC0+9bWLdJ1989e33P/A9FeR28/MP33/71Ref+KB+u6T7Jrby/OteMSEHxevl3MPbgUeefhW6CTkMXn26lOfJdOehJ5+788rdtz7AJhByO/ngrbuv3HnuyTKeL3p17jr3DyRzQylNUEoTBUm5Po/p/uT3+JIXSmmCUpooSEoPyB6llH0KpTRBKU0UJOX62B6ljH0KpTRBKU0UJKUHbI9Sxj6FUpqglCYKknJ9sEcpYZ9CKU1QShMFSekB7FFK2KdQShOU0kRBUq5P3KPk36dQShOU0kRBUnog7lHy71MopQlKaaIgKdfn1y8oztkH8jJBKU1QShMFSekN55DID6U0QSlNFCSlB1ixTVBKE5RyQ7Bim6CUJijlhmDFNkEpTVDKDcGKbYJSmqCUG4IV2wSlNEEpNwQrtglKaYJSbghWbBOU0gSl3BCs2CYopQlKuSFYsU1QShOUckOwYpuglCYo5YZgxTZBKU1Qyg3Bim2CUpqglBuCFdsEpTRBKTcEK7YJSmmCUm4IVmwTlNIEpdwQrNgmKKUJSrkhWLFNUEoTlHJDsGKboJQmKOWGYMU2QSlNUMoN8d57SOSHUpqglCYKkmI8/OK99/H64H3z9xehAVCKQilNFCzl+vzhHRSdhXf+ABkKpQBKaaJUKdfn4XsoNxPvQ4dAKRFKaaJMKT3wIkrNxrMQQikplNJEkVJ64O8oNBvVPoVSKiiliSKl9EDWrrUBIZRSA0IopQaEFCWlB1BkRiCkfykz52ZIdgRCbqBWdtYCIQf9A+0OhBQlpQdQZEYgpH8pNGE/QAil1ICQXkCRGYGQfqQsJgM3mJxbOqcJZd2Rhf+e1YQL58ZI7gyEHFysXA8I6QUUmREI6UXKCeJ+rl+O2oSyXvsc+xXThH0DIb2AIrcjPyGCSZhPhk5aG41zDTWfaZyfjCRjNFvZb1+f1g6E9FGxp7ZW5UqB36MUmvBGgJCOUqz2rdrPphKzbmz7Zh+aikzykR3i2S/RraIgpBdQ5HYSE57p1hiTdROGZsgNMplwNZBdwPnFQnYFQ/ma2YS1ddOEvQAhHaVYDMrWr6LvJGabTSiMpe3wCb/0JUBIL6DI7YhUhNDcZBqitWbC6EHkhc/LgJAefmMRN5CavDiXVcth4bGbMKArPlIT+m3W/plHv7eZ0E113s4VBSG9gCK3E01oHpyeSepsumbClaQHc/HA+UxaQiGZthUI6eE3njp3YomJ6aUJPbriYzbhmdTBSGN2oTGrJqyqQk0oPbylRrJb+oxuFQUhvYAitxNMqP09P+ihX+om1M3xFtApQjJtKxDSw28s1at1bbpkt7Zz4PcopVp33PHShNcHQjpKwTZrlPq4sMhsMqHvx5lRizehKj21HM+6Ca1BDyTTtgIhPfzGUr1WoahJVSf4rE5ASA9SSjChfcrqacKq5RCaTaiJnSoKQnoBRW5HlFkIDf2IRyQ14YW2klNt0UE6bRsQ0sNvTBNWyArtkya0IYKBDtl72k2o7UvnioKQXkCR2xFl+kvqYV+tsauZ0Mf8NMZ8Om0bENLDbyzVu9YdVTKb0LP+/VIg5MpS/LYbWU14NnRD/wucj90A3ajZwI2T3XV3IKSjlLDNth8cnGCNca+o4RlNOEWieBOq4vXQSoyG4dFQvbVpW4CQHiJfBPh9BAdmSjGhhowNVfvxBH8wo2HjhrFp2gEI6SglbHM4RXFiq2wyoQ3MWCevc0VBSC+gyO2IMvySG6GVGm3ht2/grxqrT2sHQnqIfD1FoXsAnqIoxoSyOxR01+gvpLBANzumh2mdgZCOUqptnvuz2yMMzAD5oiEdsBbxVpgQA6CeNRNK+Gur7k/WZTCh/rqjxcVCPgo4WV8h4bZ3E66Ry4Q+4nXVqBHN9KkdfxsDQjpKSbf5zJTod0lU2ZUJB/5IpngTau2NLANsmFAadj0zap2OzWnNQEgf4aZnhDy6VyvGhKIikwnPTyz2RnZq96pAyJWkFNISKrpv1g5SowntWktkFG5CNVj6c6YmDF38peRZc5lM2wqE9BD51cWj9gMfvQlX3gLG2B8jXAUIuZIUC3I7PvHHhOGHQddwVyCkoxT4KaxIrzSR6N0woXVDA+WbUDcDR3y2bakJFxg31SFUmzmZthUI6SHyBbuVaeol5jThOllMWF2uJfhjhKsAIVeTcjbUIwTlfOyG1ejoZH+jozO0udpPEim33YT+Zz2RGF9tXLa2cMO5VKxePe33d8m0rUBI/5F/7CbUXeZ0od5bSNTXTy7tAoTcQK3sDIR0lBJM6MZnK4lYbYolQm+9CVfxHgrTqiYEtjnAjz5Lwpa5DAjZ7Tf2K0rBhIQ9mRDrT8CElBwmjJfSCmLIbrHVAIRcR0pfQEhHKdGEkfpdFDL1NpowuSsk3MoE7LyAZ+h7g5Kyz8uAkP4jnyakCfWjustU71Y6ABNKeqodzqGNt6UmvFjaSBzujhQsswMQ0v9vvCcTdiKHCdkdhZ9CyHq3HYIJOyObh9R2IKT/3/jYTVjEwEy/QEhHKV39lJLFhJ1eqrEfE+Z6v0cFhByKlPQUxSgMau8OhNy+Wrk1Juz0TH9RJtSa7UvwbT6+bOUehHSUcpMcnpQ+Ttbf3lqxGNyp9bAlOpmwktIDnR7qf5MmrF4zlf39ApTSxO2VYjF4QyaspPTAw5kfKP7OwxBCKQmU0kSZUvrgt1k35/3/ggyFUgClNFGqlF54Nldf//17L67tUCiFUpopWgohhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQsih8qtf/T/4aCVJhywGOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfWZLECjoJkn"
      },
      "source": [
        "<h1>BERT 모델을 이용한 감성분류</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5861idd25QB"
      },
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertPreTrainedModel, BertModel #transformer 패키지 안에 BERT 모델 가져옴\n",
        "\n",
        "\n",
        "class SentimentClassifier(BertPreTrainedModel): # BertPreTrainedModel 상속받음\n",
        "\n",
        "  # 2개의 메소드\n",
        "    def __init__(self, config): # 생성자\n",
        "        super(SentimentClassifier, self).__init__(config) # Bert 사전학습 모델 생상자 오버라이딩\n",
        "\n",
        "        # BERT 모델\n",
        "        self.bert = BertModel(config) \n",
        "\n",
        "        # 히든 사이즈 - Bert의 출력사이즈가 hidden size\n",
        "        self.hidden_size = config.hidden_size\n",
        "\n",
        "        \n",
        "\n",
        "        # 분류할 라벨의 개수\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.linear = nn.Linear(in_features=self.hidden_size, out_features=self.num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None): \n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids) # 숫자로 받아야 함\n",
        "\n",
        "        # BERT 출력에서 CLS에 대응하는 벡터 표현 추출\n",
        "        # 선형 함수를 사용하여 예측 확률 분포로 변환\n",
        "\n",
        "        ############코드 작성 부분###############\n",
        "        # (batch_size, max_length, hidden_size) -> output, max_length는 문장의 최대 길이\n",
        "        bert_output = outputs[0]\n",
        "\n",
        "        # (batch_size, hidden_size)\n",
        "        cls_vector = bert_output[:, 0, :] # 10개 입력이 들어가면 batch size만큼 나옴\n",
        "\n",
        "        # class_output : (batch_size, num_labels)\n",
        "        cls_output = self.linear(cls_vector)\n",
        "        #########################################\n",
        "\n",
        "        return cls_output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caSL4RyA1OOm"
      },
      "source": [
        "<h1>데이터 읽고 전처리 하기</h1>\n",
        "\n",
        "<pre>\n",
        "<b>1. read_data(file_path)</b>\n",
        "  \"train_datas_wordpiece.txt\", \"test_datas_wordpiece.txt\" 파일을 읽기 위한 함수\n",
        "  \n",
        "  데이터 예시)\n",
        "    ▁아 ▁더 빙 . . ▁진짜 ▁짜 증 나 네요 ▁목소리 \\t negative\n",
        "  \n",
        "  read_file(file_path)\n",
        "  args\n",
        "    file_path : 읽고자 하는 데이터의 경로\n",
        "  return\n",
        "    datas : 영화 리뷰, 정답 라벨\n",
        "    \n",
        "    출력 예시)\n",
        "      datas = [\n",
        "        (['▁아', '▁더', '빙', '.', '.', '▁진짜', '▁짜', '증', '나', '네요', '▁목소리'], negative)\n",
        "\n",
        "        (...),\n",
        "        \n",
        "        ]\n",
        "      \n",
        "<b>2. read_vocab_data(vocab_data_path)</b>\n",
        "  \"label_vocab.txt\" 파일을 읽고 라벨을 indexing하기 위한 딕셔너리를 생성\n",
        "   \n",
        "  read_vocab_data(vocab_data_path)\n",
        "  args\n",
        "    vocab_data_path : 어휘 파일 경로\n",
        "  return  \n",
        "    term2idx : 라벨을 대응하는 index로 치환하기 위한 딕셔너리\n",
        "    idx2term : index를 대응하는 라벨로 치환하기 위한 딕셔너리\n",
        "\n",
        "<b>3. convert_data2feature(datas, max_length, tokenizer, label2idx)</b>\n",
        "  입력 데이터를 고정된 길이로 변환 후 indexing\n",
        "  Tensor로 변환\n",
        "   \n",
        "  convert_data2feature(datas, max_length, tokenizer, label2idx)\n",
        "  args\n",
        "    datas : 영화 리뷰 데이터와 대응하는 정답 라벨을 갖고 있는 리스트\n",
        "    max_length : 입력의 최대 길이\n",
        "    tokenizer : electra tokenizer 객체\n",
        "    label2idx : 라벨을 대응하는 index로 치환하기 위한 딕셔너리\n",
        "  return\n",
        "    input_ids_features : 입력 문장에 대한 index sequence\n",
        "    label_id_features : 정답을 갖고 있는 리스트\n",
        "    \n",
        "  전처리 예시)\n",
        "    tokenizing된 리뷰 데이터['▁아', '▁더', '빙', '.', '.', '▁진짜', '▁짜', '증', '나', '네요', '▁목소리', ...]\n",
        "    input_ids : [2, 3360, 28709, 18, 18, 12704, 29334, ... ]\n",
        "    label_id : [1]\n",
        " </pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOGS8rse1ZZZ"
      },
      "source": [
        "import torch\n",
        "\n",
        "# 데이터 읽기\n",
        "def read_data(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf8\") as inFile: #[[...], [...], ...]\n",
        "        lines = inFile.readlines()\n",
        "\n",
        "    datas = []\n",
        "    for line in lines:\n",
        "        # 입력 데이터를 \\t을 기준으로 분리\n",
        "        pieces = line.strip().split(\"\\t\")\n",
        "\n",
        "        # 리뷰, 정답\n",
        "        input_sequence, label = pieces[0].split(\" \"), pieces[1]\n",
        "\n",
        "        datas.append((input_sequence, label))\n",
        "\n",
        "    return datas\n",
        "\n",
        "# 사전 읽기\n",
        "def read_vocab_data(vocab_data_path):\n",
        "    term2idx, idx2term = {}, {}\n",
        "\n",
        "    with open(vocab_data_path, \"r\", encoding=\"utf8\") as inFile:\n",
        "        lines = inFile.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        term = line.strip()\n",
        "        term2idx[term] = len(term2idx)\n",
        "        idx2term[term2idx[term]] = term\n",
        "\n",
        "    return term2idx, idx2term\n",
        "\n",
        "# 데이터 전처리 \n",
        "def convert_data2feature(datas, max_length, tokenizer, label2idx): # tokenizer는 언어 모델에 포함된 객체\n",
        "    input_ids_features, label_id_features = [], []\n",
        "\n",
        "    for input_sequence, label in datas:\n",
        "\n",
        "        # CLS, SEP 토큰 추가\n",
        "        tokens = [tokenizer.cls_token] # cls_token : cls 를 붙임\n",
        "        tokens += input_sequence\n",
        "        tokens = tokens[:max_length - 1] # 정해진 max length 보다 길면 삭제 (보통 512)\n",
        "        tokens += [tokenizer.sep_token] # sep_token : sep 를 붙임\n",
        "\n",
        "        # word piece들을 대응하는 index로 치환\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # padding 생성\n",
        "        padding = [tokenizer._convert_token_to_id(tokenizer.pad_token)] * (max_length - len(input_ids)) # 90개를 padding으로 채움움\n",
        "        input_ids += padding\n",
        "\n",
        "        label_id = label2idx[label]\n",
        "\n",
        "        # 변환한 데이터를 각 리스트에 저장\n",
        "        input_ids_features.append(input_ids)\n",
        "        label_id_features.append(label_id)\n",
        "\n",
        "    # 변환한 데이터를 Tensor 객체에 담아 반환\n",
        "    input_ids_features = torch.tensor(input_ids_features, dtype=torch.long)\n",
        "    label_id_features = torch.tensor(label_id_features, dtype=torch.long)\n",
        "\n",
        "    return input_ids_features, label_id_features"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urLIOIHT779c"
      },
      "source": [
        "<h1>BERT 모델 학습</h1>\n",
        "\n",
        "<pre>\n",
        "<b>1. read_data(file_path) 함수를 사용하여 학습 데이터 읽기</b>\n",
        "\n",
        "<b>2. read_vocab_data(vocab_data_path) 함수를 사용하여 어휘 딕셔너리 생성</b>\n",
        "\n",
        "<b>3. convert_data2feature(datas, max_length, tokenizer, label2idx) 함수를 사용하여 데이터 전처리</b>\n",
        "\n",
        "<b>4. BERT 모델 객체 선언 후 사전 학습 파일 불러옴</b>\n",
        "\n",
        "<b>5. epoch 마다 학습한 모델 파일 저장</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsYLc2YK8eNc"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import (DataLoader, TensorDataset, RandomSampler)\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from transformers import BertConfig\n",
        "from tokenization_kobert import KoBertTokenizer\n",
        "\n",
        "# Train\n",
        "def train(config):\n",
        "    # BERT config 객체 생성\n",
        "    bert_config = BertConfig.from_pretrained(pretrained_model_name_or_path=config[\"pretrained_model_name_or_path\"],\n",
        "                                             cache_dir=config[\"cache_dir_path\"])\n",
        "    setattr(bert_config, \"num_labels\", config[\"num_labels\"]) # 기존 BERT config에 프로그램에서 새로 정의한 config 추가가\n",
        "\n",
        "    # BERT tokenizer 객체 생성\n",
        "    bert_tokenizer = KoBertTokenizer.from_pretrained(pretrained_model_name_or_path=config[\"pretrained_model_name_or_path\"],\n",
        "                                                     cache_dir=config[\"cache_dir_path\"]) # KoBertTokenizer\n",
        "\n",
        "    # 라벨 딕셔너리 생성\n",
        "    label2idx, idx2label = read_vocab_data(vocab_data_path=config[\"label_vocab_data_path\"])\n",
        "\n",
        "    # 학습 및 평가 데이터 읽기\n",
        "    train_datas = read_data(file_path=config[\"train_data_path\"])\n",
        "\n",
        "    # 입력 데이터 전처리\n",
        "    train_input_ids_features, train_label_id_features = convert_data2feature(datas=train_datas,\n",
        "                                                                             max_length=config[\"max_length\"],\n",
        "                                                                             tokenizer=bert_tokenizer,\n",
        "                                                                             label2idx=label2idx)\n",
        "\n",
        "    # 학습 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
        "    # batch size만큼 랜덤 샘플링\n",
        "    train_dataset = TensorDataset(train_input_ids_features, train_label_id_features)\n",
        "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=config[\"batch_size\"],\n",
        "                                  sampler=RandomSampler(train_dataset))\n",
        "\n",
        "    # 사전 학습된 BERT 모델 파일로부터 가중치 불러옴\n",
        "    model = SentimentClassifier.from_pretrained(pretrained_model_name_or_path=config[\"pretrained_model_name_or_path\"],\n",
        "                                                cache_dir=config[\"cache_dir_path\"], config=bert_config).cuda()\n",
        "\n",
        "    # loss를 계산하기 위한 함수\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 모델 학습을 위한 optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "    for epoch in range(config[\"epoch\"]): # 한번 전체를 학습하는데 1 epoch\n",
        "        model.train()\n",
        "\n",
        "        total_loss = []\n",
        "        for batch in train_dataloader: # dataloader에서 batch size만큼 가져옴\n",
        "            batch = tuple(t.cuda() for t in batch)\n",
        "            input_ids, label_id = batch\n",
        "\n",
        "            # 역전파 단계를 실행하기 전에 변화도를 0으로 변경\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 모델 예측 결과\n",
        "            hypothesis = model(input_ids) # Batch size만큼 2개씩 있음\n",
        "\n",
        "            # loss 계산\n",
        "            loss = loss_func(hypothesis, label_id)\n",
        "\n",
        "            # loss 값으로부터 모델 내부 각 매개변수에 대하여 gradient 계산\n",
        "            loss.backward()\n",
        "            # 모델 내부 각 매개변수 가중치 갱신\n",
        "            optimizer.step()\n",
        "\n",
        "            # batch 단위 loss 값 저장\n",
        "            total_loss.append(loss.data.item())\n",
        "\n",
        "        bert_config.save_pretrained(save_directory=config[\"output_dir_path\"])\n",
        "        model.save_pretrained(save_directory=config[\"output_dir_path\"])\n",
        "\n",
        "        print(\"Average loss : {}\".format(np.mean(total_loss)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20OC-TY8FIFj"
      },
      "source": [
        "<h1>BERT 모델 평가</h1>\n",
        "\n",
        "<pre>\n",
        "<b>1. read_data(file_path) 함수를 사용하여 평가 데이터 읽기</b>\n",
        "\n",
        "<b>2. read_vocab_data(vocab_data_path) 함수를 사용하여 어휘 딕셔너리 생성</b>\n",
        "\n",
        "<b>3. convert_data2feature(datas, max_length, tokenizer, label2idx) 함수를 사용하여 데이터 전처리</b>\n",
        "\n",
        "<b>4. BERT 모델 객체 선언 후 기존에 학습한 모델 파일 불러옴</b>\n",
        "\n",
        "<b>5. 학습한 BERT 모델 평가</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORSC_y9Nto04"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import (DataLoader, TensorDataset, SequentialSampler)\n",
        "\n",
        "from transformers import BertConfig\n",
        "from tokenization_kobert import KoBertTokenizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Test\n",
        "def test(config):\n",
        "    # BERT config 객체 생성\n",
        "    bert_config = BertConfig.from_pretrained(pretrained_model_name_or_path=config[\"output_dir_path\"],\n",
        "                                             cache_dir=config[\"cache_dir_path\"])\n",
        "\n",
        "    # BERT tokenizer 객체 생성 (기존 BERT tokenizer 그대로 사용)\n",
        "    bert_tokenizer = KoBertTokenizer.from_pretrained(pretrained_model_name_or_path=config[\"pretrained_model_name_or_path\"],\n",
        "                                                     cache_dir=config[\"cache_dir_path\"])\n",
        "\n",
        "    # 라벨 딕셔너리 생성\n",
        "    label2idx, idx2label = read_vocab_data(vocab_data_path=config[\"label_vocab_data_path\"])\n",
        "\n",
        "    # 평가 데이터 읽기\n",
        "    test_datas = read_data(file_path=config[\"test_data_path\"])\n",
        "    test_datas = test_datas[:100]\n",
        "\n",
        "    # 입력 데이터 전처리\n",
        "    test_input_ids_features, test_label_id_features = convert_data2feature(datas=test_datas,\n",
        "                                                                           max_length=config[\"max_length\"],\n",
        "                                                                           tokenizer=bert_tokenizer,\n",
        "                                                                           label2idx=label2idx)\n",
        "\n",
        "    # 평가 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
        "    test_dataset = TensorDataset(test_input_ids_features, test_label_id_features)\n",
        "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=config[\"batch_size\"],\n",
        "                                 sampler=SequentialSampler(test_dataset))\n",
        "\n",
        "    # 학습한 모델 파일로부터 가중치 불러옴\n",
        "    model = SentimentClassifier.from_pretrained(pretrained_model_name_or_path=config[\"output_dir_path\"],\n",
        "                                                cache_dir=config[\"cache_dir_path\"], config=bert_config).cuda()\n",
        "\n",
        "    model.eval() # 평가모드\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.cuda() for t in batch)\n",
        "        input_ids, label_id = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # 모델 예측 결과\n",
        "            hypothesis = model(input_ids)\n",
        "            # 모델의 출력값에 softmax와 argmax 함수를 적용\n",
        "            hypothesis = torch.argmax(torch.softmax(hypothesis, dim=-1), dim=-1)\n",
        "\n",
        "        # Tensor를 리스트로 변경\n",
        "        hypothesis = hypothesis.cpu().detach().numpy().tolist()\n",
        "        label_id = label_id.cpu().detach().numpy().tolist()\n",
        "\n",
        "        for index in range(len(input_ids)):\n",
        "            input_tokens = bert_tokenizer.convert_ids_to_tokens(input_ids[index])\n",
        "            input_sequence = bert_tokenizer.convert_tokens_to_string(input_tokens[1:input_tokens.index(bert_tokenizer.sep_token)])\n",
        "            predict = idx2label[hypothesis[index]]\n",
        "            correct = idx2label[label_id[index]]\n",
        "\n",
        "            print(\"입력 : {}\".format(input_sequence))\n",
        "            print(\"출력 : {}, 정답 : {}\\n\".format(predict, correct))\n",
        "\n",
        "    # 정확도 출력\n",
        "    print(\"Accuracy : {}\".format(accuracy_score(hypothesis, label_id)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbtyjwvtFxf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0e3628-7870-4335-8ead-8c52fd92a01f"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "if(__name__==\"__main__\"):\n",
        "    root_dir = \"/gdrive/My Drive/NLP/week3/4-2. Pretrained LM1\"\n",
        "    save_dir = os.path.join(root_dir, \"save\")\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    cache_dir = os.path.join(root_dir, \"cache\")\n",
        "    \n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    if not os.path.exists(cache_dir):\n",
        "        os.makedirs(cache_dir)\n",
        "\n",
        "\n",
        "    config = {\"mode\": \"train\",\n",
        "              \"train_data_path\": os.path.join(root_dir, \"train_datas_wordpiece.txt\"),\n",
        "              \"test_data_path\": os.path.join(root_dir, \"test_datas_wordpiece.txt\"),\n",
        "              \"output_dir_path\": output_dir,\n",
        "              \"save_dir_path\": save_dir,\n",
        "              \"cache_dir_path\": cache_dir,\n",
        "              \"pretrained_model_name_or_path\": \"monologg/kobert\",\n",
        "              \"label_vocab_data_path\": os.path.join(root_dir, \"label_vocab.txt\"),\n",
        "              \"num_labels\": 2,\n",
        "              \"max_length\": 142,\n",
        "              \"epoch\":10,\n",
        "              \"batch_size\":64\n",
        "              }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'KoBertTokenizer'.\n",
            "Some weights of SentimentClassifier were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['linear.weight', 'linear.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss : 0.5466813595051978\n",
            "Average loss : 0.35647575196566855\n",
            "Average loss : 0.25984031569426225\n",
            "Average loss : 0.18614887337016453\n",
            "Average loss : 0.12832394458211152\n",
            "Average loss : 0.09586481693064332\n",
            "Average loss : 0.07476156970758917\n",
            "Average loss : 0.06418753172727718\n",
            "Average loss : 0.049369262632243574\n",
            "Average loss : 0.04125183761997777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(__name__==\"__main__\"):\n",
        "    root_dir = \"/gdrive/My Drive/NLP/week3/4-2. Pretrained LM1\"\n",
        "    save_dir = os.path.join(root_dir, \"save\")\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    cache_dir = os.path.join(root_dir, \"cache\")\n",
        "    \n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    if not os.path.exists(cache_dir):\n",
        "        os.makedirs(cache_dir)\n",
        "\n",
        "\n",
        "    config = {\"mode\": \"test\",\n",
        "              \"train_data_path\": os.path.join(root_dir, \"train_datas_wordpiece.txt\"),\n",
        "              \"test_data_path\": os.path.join(root_dir, \"test_datas_wordpiece.txt\"),\n",
        "              \"output_dir_path\": output_dir,\n",
        "              \"save_dir_path\": save_dir,\n",
        "              \"cache_dir_path\": cache_dir,\n",
        "              \"pretrained_model_name_or_path\": \"monologg/kobert\",\n",
        "              \"label_vocab_data_path\": os.path.join(root_dir, \"label_vocab.txt\"),\n",
        "              \"num_labels\": 3,\n",
        "              \"max_length\": 142,\n",
        "              \"epoch\":10,\n",
        "              \"batch_size\":64\n",
        "              }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODsIdYFzTC8k",
        "outputId": "b11304e2-9e1a-42a6-a345-aea7978e2b9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'KoBertTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 굳 ᄏ\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : GDNTOPCLASSINTHECLUB\n",
            "출력 : positive, 정답 : negative\n",
            "\n",
            "입력 : 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
            "출력 : positive, 정답 : negative\n",
            "\n",
            "입력 : 지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 음악이 주가 된, 최고의 음악영화\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 진정한 쓰레기\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 마치 미국애니에서 튀어나온듯한 창의력없는 로봇디자인부터가,고개를 젖게한다\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 갈수록 개판되가는 중국영화 유치하고 내용없음 폼잡다 끝남 말도안되는 무기에 유치한cg남무 아 그립다 동사서독같은 영화가 이건 3류아류작이다\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 이별의 아픔뒤에 찾아오는 새로운 인연의 기쁨 But, 모든 사람이 그렇지는 않네..\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 괜찮네요오랜만포켓몬스터[UNK]밌어요\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 한국독립영화의 한계 그렇게 아버지가 된다와 비교됨\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 청춘은 아름답다 그 아름다움은 이성을 흔들어 놓는다. 찰나의 아름다움을 잘 포착한 섬세하고 아름다운 수채화같은 퀴어영화이다.\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 눈에 보이는 반전이었지만 영화의 흡인력은 사라지지 않았다.\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : \"\"\"스토리, 연출, 연기, 비주얼 등 영화의 기본 조차 안된 영화에 무슨 평을 해. 이런 영화 찍고도 김문옥 감독은 \"\"\"\"내가 영화 경력이 몇OO인데 조무래기들이 내 영화를 평론해?\"\"\"\" 같은 마인드에 빠져있겠지?\"\"\"\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 소위 [UNK]문가라는 평점은 뭐냐?\n",
            "출력 : negative, 정답 : positive\n",
            "\n",
            "입력 : 최고!!!!!!!!!!!!!!!!\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 발연기 도저히 못보겠다 진짜 이렇게 연기를 못할거라곤 상상도 못했네\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 나이스\n",
            "출력 : negative, 정답 : positive\n",
            "\n",
            "입력 : 별 재미도없는거 우려먹어 .... 챔프에서 방송 몇번했더라 ? ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : '13일의 금요일', '나이트메어'시리즈와 함께 가장 많은 시리즈를 양산해냈던 헬레이저 시리즈의 첫편. 작가의 상상력이 돋보이는 작품이며, 갈고리로 사지찢는 고어씬은 지금보더라도 상당히 잔인하고 충격적이다.\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 나름 교훈돋기는 하지만 어쩔수없이 저평점 받을수밖에 없는 저질섹스코미디\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 꽤 재밌게 본 영화였다!\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 민주화 시대의 억눌린 영혼의 관음적인 욕구 분출.인상적이다.\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 일본 천황이 미국으로부터 받은 면죄부의 긴박한 과정을 루즈하고 지저분하게 늘어놓았다.\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 괜히 나올 때 어미 알 건드려서 긁어 부스름 만들었다는 분이 저 아래 보이던데, 영화 제대로 안 봤네. 알이 딱 까지면서 새끼가 나오려 했음. 그냥 가면 그 놈 한테 당했을 것임. 한 놈, 두 놈 막 나올 게 뻔했으니 작살낼 수 밖에 없었다.\n",
            "출력 : negative, 정답 : positive\n",
            "\n",
            "입력 : 50번은 봤네요어[UNK] 이렇게 잘만들었을까\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 실화라서더욱아름답고[UNK]하네요...많이울었어요벌써4년이란시간이흘렀네요\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 이건뭐 노답이네 80~90년대 어린이 영화좀 보고 본받아라!\n",
            "출력 : positive, 정답 : negative\n",
            "\n",
            "입력 : 지금까지 본 영화중 마음이 가장 따뜻해지는 영화.\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 너무너무 재밌다\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 안보면 후회[UNK]...\n",
            "출력 : negative, 정답 : positive\n",
            "\n",
            "입력 : 평점1점도 주기싫어지는 영화 배우나 감독이라는 사람이나 영화판에서 안봐으면 한다 그리고 평점알바생들 너무 티난다\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 정말,진짜,표현할수 없는 영화...\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 엉성한 액션에, 시나리오는 왜그러지.. 막판에 대동단결??\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 101, 102.. 103은 못나올것 같다.\n",
            "출력 : positive, 정답 : negative\n",
            "\n",
            "입력 : ....재미가없어요 시간이 아깝고\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 북괴는 우리의 주적일뿐이다.\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : ᄏᄏᄏ 난생처음 로그인하고 평점남기네요.. 개빡쳐서.. 알바들 속지마세요 이런 ᄀ [UNK]같은 시간낭비가. 아놔진짜평점 마이너스 별오만개\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 셰익스피어는 셰익스피어고 이영화는 이영화.\n",
            "출력 : positive, 정답 : negative\n",
            "\n",
            "입력 : EBS 한국영화특선 해서 봤다.Biff 개막작 선정되서 [UNK]까 궁금 했었는데 봐도 이율 모르겠다...\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 뭐야??라는 말 밖에는...\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 이게 영화야?\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 애니는 일본이 갑인듯.\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 롭 코헨의 몰락의 OO점\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 감동적이다....\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 은빛날개의 조종사\n",
            "출력 : positive, 정답 : negative\n",
            "\n",
            "입력 : 마음이1을보신분들은 이해하시겟지만 2는망장입니다 졸작이죠 솔직히말해선;; 그이유는 예를들면 엽기적인그녀는 긴시간을두고 코메디 멜로를 그렷습니다 하지만 이영화는 단시간 10분안에 모든것을 소화하려는 욕심 코믹하다 3분채안돼갑자기 생뚱맞게 슬픈음악이깔리고\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 이런스타일 액션영화 굿굿!!\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 제임스 헷필드 50먹고 더 파워풀해졌어ᄏᄏᄏᄏ\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 돈만있으면 내가 이것보단 더잘만들겠따 ᄏ\n",
            "출력 : positive, 정답 : negative\n",
            "\n",
            "입력 : 레이토와 다미앙의 시원한 액션은 어디갔나 [UNK]\n",
            "출력 : positive, 정답 : negative\n",
            "\n",
            "입력 : 내 참, 이딴 걸 드라마라고.... 그냥 이건 세계보건기구에서 발암물질로 올려야 한다.\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 아 극장에서 아무 기대없이 들어갔다가 감탄하면서 보고 나왔는데. 2001년도 였구나 그 때가.\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 아이디어가 아주 좋다 재밌다\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 난 재밌던데 평점 왜케 낮지 \";\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 역사얘기보다 영화배우, 감독들들에게 더 관심이 간다\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 몇년만에 아메리칸조크보고 웃어보는거지. 하아이맛이야바로\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 재밌다! 내용도 신선하고 의미도있으며 연기도 좋고 영상도좋다~~\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 여름이면 한결같이 생각나는 드라마\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 콩콩~~~~ᄏ[UNK]\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : ...으...뭐 의도는 좋아봤자 전달이 돼야지;\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 아빠가 낚여서 본적 있다나 슈래기 영화\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 엠비씨 무비채널에서 봤는데 또 봐도 엄청 [UNK]나네여 ..\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 어우.. 이게 진짜 무서웠어요?? 진짜로? 시간 아까웠습니다.\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 몇번을 봐도 볼때마다 재밌다\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 재미있게 잘봤습니다 후속편을 기다리게 만드네요\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 결말 뻔히 알면서 보는데도 너무 슬프고 많이 울었음.\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 한번본적은업지만재미있을것같다\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 성경에 보면 지나치게 의인도 되지 말고 지혜롭게 되지도 말라고 했다. 주인공의 지나친 착한남자 컴플렉스는 결국 모든걸 엉망으로 만들었다.직장에서 해고되고 부인에게 거부당하고,그 모든 터전을 잃을만큼 불륜으로 생긴 아이를 보러가는게 그리 중요했을까???\n",
            "출력 : negative, 정답 : positive\n",
            "\n",
            "입력 : 미친놈들 집합소네 연출력 빵점, 스토리 빵점. 구성빵점\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 하...작은 그림보고 기대했는데..수염..눈색깔도 뭐..이건 뭐 원작 비충실..[UNK]\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 볼 거 없을때 봐도 재미 없는 영화!\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 관객모독 관객모독 관객모독 관객모독\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 이런내용완전좋다[UNK]\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 쇼타군 넘 좋아 돈키호테 대박 재밌음\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 참 대단한것 같습니다천...재..?\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 볼만함\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 제시카 알바가 벗고 달려드는데 [UNK]까는게 말이 되냐?\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 솔직히 이건 C급 그 이하의 영화이긴 함 ᄒᄒ;\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 개성있는 몬스터들과 귀여운 여자아이가 만나 뿜어내는 매력에 퐁당 빠졌다\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 제목이 찰지구나ᄏᄏᄏ\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 1956년 작품이라는게 믿기지가 않을정도로 디테일하다! 안소니 퀸의 명연기 또한 물론~\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 아찔한 사랑 줄다리기???\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 재미있었다! 또봐야징ᄒ\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 중간에 화면이 좀 끊기는것 빼곤 넘 좋았어요~\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 이 영화를 말하는데 긴 단어는 필요없다. 재수없는 졸작 이거면 충분하다.\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 최고최고! 바다까지! 4차원 고양이 로봇 도라에몽과 함께하는 진구와 친구들의 미지 탐험 이야기!우주꺼지 갔음 좋겠당~\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 완전 [UNK]없음..\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 로코 굉장히 즐겨보는데, 이 영화는 좀 별로였다. 뭔가 사랑도 개그도 억지스런 느낌..\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 후속작 계획은 없나요..? [UNK]\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 엔딩때까지 음성 넣은 것은 오버의 극치다\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 단 두마디 '감동'\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 뭘 만든 건가?\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 전기톱은못들고다니는데 엔진톱이겠죠\n",
            "출력 : positive, 정답 : negative\n",
            "\n",
            "입력 : 완전 재밌엇는데 왜 평점이??\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 제임스 완이 내 목표임 [UNK]\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 1점고 아깝다. 개막장 영화의 원조라고나 할까.아내와 사별한 지 얼마나 지났다고 딴 여자들 만나고 다니다가 결국 맥 라이언한테 꽂힌 톰 행크스나약혼자 두고 톰 행크스랑 썸 타다가 결국엔 약혼자 버리고 톰행크스한테 쪼르르 달려가는 맥 라이언이나.\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "입력 : 가끔 문득 생각나서 다시보는 영화..색감이 정말 예술이죠 강렬하고 화려하고..츠지야안나의 너무도 아름답던 리즈시절도 볼 수 있고..\n",
            "출력 : positive, 정답 : positive\n",
            "\n",
            "입력 : 걸작은 몇안되고 졸작들만 넘쳐난다.\n",
            "출력 : negative, 정답 : negative\n",
            "\n",
            "Accuracy : 0.9444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy : 0.8333333333333334 -> Accuarcy : 0.9444444444444444 으로 바뀌었다\n",
        "\n",
        "BERT 모델 아키텍처 부분에서 outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids)\n",
        "\n",
        "● token_type_ids : 각 token이 어떤 문장에 속하는지를 나타내는 리스트이다. BERT는 한 번에 두문장(sentence A, sentence B)을 입력으로 받을 수 있는데, bert-based-uncased tokenizer는 sentence A에 속하는 token에는 0을, sentence B에 속하는 token에는 1을 부여\n",
        "\n",
        "● attention_mask : attention 연산이 수행되어야 할 token과 무시해야 할 token을 구별하는 정보가 담긴 리스트. bert-base-uncased tokenizer는 attention 연산이 수행되어야 할, 일반적인 token에는 1을 부여하고, padding과 같이 attention 연산이 수행될 필요가 없는 token들에는 0을 부여한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "d5RP5qLLU3If"
      }
    }
  ]
}